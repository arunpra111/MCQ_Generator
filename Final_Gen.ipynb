{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages in Google Colab\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install rake-nltk\n",
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19RTUZsIpD4v",
        "outputId": "5c49bf4c-ed74-4a75-b55f-ab16905293b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: rake-nltk in /usr/local/lib/python3.10/dist-packages (1.0.6)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.6.2 in /usr/local/lib/python3.10/dist-packages (from rake-nltk) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.6.2->rake-nltk) (4.66.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required libraries\n",
        "import nltk\n",
        "from transformers import pipeline\n",
        "from rake_nltk import Rake\n",
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "id": "p56-wDRzpDvY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Fix for LookupError\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo8KBNpXpDsV",
        "outputId": "1b4ebdb6-a757-4b40-890a-7e6b9ad4a144"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarizer\n",
        "def summarize_text(text):\n",
        "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "    summary = summarizer(text, max_length=130, min_length=30, do_sample=False)\n",
        "    return summary[0]['summary_text']\n",
        "\n",
        "# Keyword Extractor\n",
        "def extract_keywords(text):\n",
        "    r = Rake()\n",
        "    r.extract_keywords_from_text(text)\n",
        "    keywords = r.get_ranked_phrases()[:5]  # Return top 5 keywords\n",
        "    return keywords\n",
        "\n",
        "# Sentence Tokenizer\n",
        "def tokenize_sentences(text):\n",
        "    sentences = nltk.sent_tokenize(text)\n",
        "    return sentences\n",
        "\n",
        "# Sentence Mapper\n",
        "def map_sentences_to_keywords(sentences, keywords):\n",
        "    mapped = []\n",
        "    for sentence in sentences:\n",
        "        for keyword in keywords:\n",
        "            if keyword.lower() in sentence.lower():\n",
        "                mapped.append((sentence, keyword))\n",
        "                break\n",
        "    return mapped\n",
        "\n",
        "# Distractor Generator\n",
        "def generate_distractors(word, n=3):\n",
        "    distractors = []\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            if lemma.name().lower() != word.lower():\n",
        "                distractors.append(lemma.name())\n",
        "                if len(distractors) == n:\n",
        "                    return distractors\n",
        "    if not distractors:\n",
        "        from random import sample\n",
        "        all_words = list(set([w for s in wordnet.all_synsets() for w in s.lemma_names()]))\n",
        "        distractors = sample([w for w in all_words if w.lower() != word.lower()], min(n, len(all_words)))\n",
        "    return distractors"
      ],
      "metadata": {
        "id": "IMnCe7evpTG6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main MCQ Generation Function\n",
        "def generate_mcqs(text):\n",
        "    summary = summarize_text(text)\n",
        "    keywords = extract_keywords(summary)\n",
        "    sentences = tokenize_sentences(summary)\n",
        "    mapped = map_sentences_to_keywords(sentences, keywords)\n",
        "\n",
        "    mcqs = []\n",
        "    for sentence, keyword in mapped:\n",
        "        distractors = generate_distractors(keyword)\n",
        "        if distractors:\n",
        "            mcqs.append({\n",
        "                'question': sentence.replace(keyword, \"________\"),\n",
        "                'answer': keyword,\n",
        "                'distractors': distractors\n",
        "            })\n",
        "    return mcqs"
      ],
      "metadata": {
        "id": "lh9j1W_rpSyU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fA14OZHgnQ2M"
      },
      "outputs": [],
      "source": [
        "# Function to display MCQs\n",
        "def display_mcqs(mcqs):\n",
        "    if not mcqs:\n",
        "        print(\"No MCQs were generated. This might be due to difficulties in finding suitable distractors.\")\n",
        "        return\n",
        "\n",
        "    for i, mcq in enumerate(mcqs, 1):\n",
        "        print(f\"\\nQuestion {i}:\")\n",
        "        print(mcq['question'])\n",
        "        options = [mcq['answer']] + mcq['distractors']\n",
        "        for j, option in enumerate(options):\n",
        "            print(f\"{chr(65 + j)}. {option}\")\n",
        "        print(f\"Answer: {mcq['answer']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage (input directly in Colab)\n",
        "text = \"\"\"\n",
        "Once upon a time, there was a wood on a hill in the outskirts of the city. There was a small stone hut next to the wood. The hut was surrounded by a gray wooden fence. A couple lived inside this hut.\n",
        "\n",
        "Men and women had only one wish. They wish to have a beautiful daughter to take care of and raise. They are not sure that they will be wonderful parents.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\nGenerating MCQs...\\n\")\n",
        "mcqs = generate_mcqs(text)\n",
        "display_mcqs(mcqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-13cDf_wnpOF",
        "outputId": "0f5b015c-351f-41bd-ab93-daf3b5bbbdfc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating MCQs...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 130, but your input_length is only 87. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=43)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question 1:\n",
            "Once upon a time, there was a ________ on a hill in the outskirts of the city.\n",
            "A. wood\n",
            "B. forest\n",
            "C. woods\n",
            "D. Natalie_Wood\n",
            "Answer: wood\n",
            "\n",
            "Question 2:\n",
            "The hut was surrounded by a ________.\n",
            "A. gray wooden fence\n",
            "B. posthypnotic_amnesia\n",
            "C. comminute\n",
            "D. cultural_anthropology\n",
            "Answer: gray wooden fence\n",
            "\n",
            "Question 3:\n",
            "A ________ this hut.\n",
            "A. couple lived inside\n",
            "B. English_plantain\n",
            "C. Upjohn\n",
            "D. dip_into\n",
            "Answer: couple lived inside\n",
            "\n",
            "Question 4:\n",
            "They wish to have a beautiful daughter to ________ of and raise.\n",
            "A. take care\n",
            "B. acidulent\n",
            "C. autogenic_therapy\n",
            "D. Sjaelland\n",
            "Answer: take care\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WVU1KsVlnpLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "81Gs_gpvnpJG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kGr8lCPKno5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}